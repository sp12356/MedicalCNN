{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f1a84-0a19-4158-b4af-9ce0f1759178",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63261a49-0591-4eb6-9c22-74728d309837",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show tensorflow\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec17f83-a21d-437d-8d56-fea20c8bb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow numpy pandas matplotlib opencv-python matplotlib\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb5c3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44ce9c-06a7-47a7-8274-b67fd66a421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a72bf-a741-4549-be43-d8f91b27a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imghdr\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1503f9-cd96-47ae-a9f0-c99bfb2d1fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Alzheimer_s Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d52fe-4863-4c42-b17b-a74182bb1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg','bmp','png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbcf956-1055-4ef9-9bfc-8eb098654f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7eb2f-a812-4a65-86a5-ae7251716917",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433e205-31a4-4abd-bdfd-07d0c2f26f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `data_dir` contains 'train' and 'test' directories.\n",
    "sub_dirs = ['train', 'test']\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "data_dir = 'Alzheimer_s Dataset'  # Replace with your base data directory\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']  # The acceptable image extensions\n",
    "\n",
    "\n",
    "# Loop through the subdirectories 'train' and 'test'\n",
    "any_image_not_good = False\n",
    "for sub_dir in data_dir:\n",
    "    sub_dir_path = os.path.join(data_dir, sub_dir)\n",
    "    \n",
    "    \n",
    "    # Check if it's a directory before proceeding\n",
    "    if os.path.isdir(sub_dir_path):\n",
    "        # Loop through each image file in the category folder\n",
    "        for image_file in os.listdir(sub_dir_path):\n",
    "            image_path = os.path.join(sub_dir_path, image_file)                \n",
    "            if image_file.startswith('.'):  # Skip hidden files like .DS_Store\n",
    "                continue\n",
    "            try:\n",
    "                img = cv2.imread(image_path)\n",
    "                tip = imghdr.what(image_path)\n",
    "                if tip not in image_exts:\n",
    "                    print('Image not in ext list {}'.format(image_path))\n",
    "                    any_image_not_good = True\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Issue with image {}: {}'.format(image_path, e))\n",
    "                any_image_not_good = True\n",
    "print(any_image_not_good)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8dbd2-afbf-46d0-bed7-26581868fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = ['.jpeg', '.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6d3c1-1cde-426b-a819-48026b95e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths[0]\n",
    "image_path = os.path.join('Alzheimer_s Dataset','Mild_Demented', 'mild_2.jpg')\n",
    "print(os.path.exists(image_path))  # Should return True if the path is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647570a9-e9c7-41d5-8215-ccd238a3efad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b572512-9fcc-4098-9651-4c901590b06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ddd01-ec8a-45f0-963c-80c7632060c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43093344-c726-4cf2-93d6-9d0fcad780d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8238a1f-179e-4ec1-ad30-6ef0932dd8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dacd25-c47d-4476-9dfe-1922e40bad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join('Alzheimer_s Dataset', 'Mild_Demented', 'mild_2.jpg'))\n",
    "if img is None:\n",
    "    print(\"Image not loaded.\")\n",
    "else:\n",
    "    print (\"Image loaded successfully\")\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Assuming you have checked img is not None\n",
    "img = cv2.imread(os.path.join('Alzheimer_s Dataset', 'Mild_Demented', 'mild_2.jpg'))\n",
    "if img is not None:\n",
    "    # Convert from BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title('Loaded Image')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Failed to load image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759f26b-5e54-41f1-b4ae-fac52726d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b94831e-ac1d-48f4-9578-84e6420d8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1804b1-3627-45c4-88ee-9c36b8817bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "main_subdir_path = 'Alzheimer_s Dataset'  # Replace with your base directory, which contains 'train' and 'test' subdirectories\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']  # Your list of image extensions\n",
    "\n",
    "# Initialize variables\n",
    "first_image_shape = None\n",
    "image_size_mismatch = False\n",
    "count = 0\n",
    "\n",
    "# Loop through the main subdirectories ('train' and 'test')\n",
    "for category_subdir in os.listdir(main_subdir_path):\n",
    "    category_subdir_path = os.path.join(main_subdir_path, category_subdir)\n",
    "    if os.path.isdir(category_subdir_path):\n",
    "        # Loop through each image within the category subdirectory\n",
    "        for image_name in os.listdir(category_subdir_path):\n",
    "            # Construct the full path to the image\n",
    "            count = count + 1\n",
    "            image_path = os.path.join(category_subdir_path, image_name)\n",
    "            # Read the image using cv2\n",
    "            image = cv2.imread(image_path)\n",
    "            # Proceed only if the image was read correctly\n",
    "            if image is not None and any(image_name.lower().endswith(ext) for ext in image_exts):\n",
    "                # If first_image_shape is not set, set it now\n",
    "                if first_image_shape is None:\n",
    "                    first_image_shape = image.shape\n",
    "                    print(f\"Reference size set to: {first_image_shape}\")\n",
    "                # If the current image size does not match the first image size, print a message\n",
    "                elif image.shape != first_image_shape:\n",
    "                    print(f\"Size mismatch in {image_path}: expected {first_image_shape}, got {image.shape}\")\n",
    "                    image_size_mismatch = True\n",
    "print(count)\n",
    "if not image_size_mismatch:\n",
    "    print(\"All images across all categories and sets are of the same size.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744010b0-5216-455c-a07b-e32f8ad4791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9a6eb-4f12-4ebd-84f9-513050567993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "current = os.getcwd()\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import io\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af42575-e1eb-4f2a-b82d-9d80a7480381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46622832-ea94-4483-8e05-5979960d5ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5136cd-9fa8-402c-9d2d-e53f9b8e1045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d59f4-da3c-4432-9912-84551ea85007",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aa2ec6-2392-4034-a155-6b033f00f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Hello, TensorFlow!\")\n",
    "\n",
    "# Test TensorFlow operation\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "tf.print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae825ff8-7f3f-4203-b407-2218563b9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('Alzheimer_s Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0219f-a355-4d20-88c8-a16a5834c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130d115-b5c2-4594-8552-64fc32e99aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7463b-287a-4f0e-b862-4747f3ddb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch)\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c7c1a-22fe-435b-9954-2d81d39888fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('Alzheimer_s Dataset')\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()\n",
    "len(batch)\n",
    "batch[0]\n",
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b20baa-768b-499c-a47d-a90168d3a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c29b87-7014-4a5b-af36-9cd4a8c68c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699f4f8-4a34-45be-b3d5-0f3354dd335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = batch[0]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6ab19-3a45-4acd-b9f2-896875a58f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145fbbce-53e2-4c20-8e31-91647dd9ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61e0a3-8a99-465d-96bb-e5ee404cd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    " scaled = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82201f-7e53-45cf-9197-2d4598d9fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = scaled.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692aa999-ca1f-4fe5-ba94-48fe47febba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5ff8c-f8e1-43c5-a7a7-28af6fd1c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ddba6d-93b2-4746-9bde-94c60f3e8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)\n",
    "print(train_size)\n",
    "print(val_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1c2f6-4c55-413b-a8be-4e5e7ca600c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = data.take(train_size).cache().shuffle(1000).repeat()\n",
    "val = data.skip(train_size).take(val_size).cache().repeat()\n",
    "test = data.skip(train_size + val_size).take(test_size).cache()\n",
    "\n",
    "\n",
    "train_iterator = train.as_numpy_iterator()\n",
    "val_iterator = val.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a4399-6ebe-4700-9b64-ed5eb4d67d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d3847-e07b-4e5c-b729-47ea700582c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74df47b-1e8e-4ecd-954a-200312e144b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23695f5-4700-4c0a-b7e7-a2e25b883082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Ensure that the necessary components are imported correctly\n",
    "# Define the input shape\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# Create the Sequential model and include dropout and early stopping\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# Print the model summary to confirm setup\n",
    "print(model.summary())\n",
    "\n",
    "# If you have a training and validation set prepared, you can attempt a test run with a very small number of epochs and a small batch size to see if it works:\n",
    "# model.fit(x_train, y_train, epochs=5, batch_size=16, validation_data=(x_val, y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48150f82-9817-4f2c-982d-b52330ef6fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e32e4-f868-4cb9-828b-ad7fb1b84fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde83d0-c54e-4657-9b74-beaf5f6e1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be0a87-c7e4-472b-a120-34ed04ccd24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_encode(labels, num_classes=4):\n",
    "    return tf.one_hot(labels, depth=num_classes)\n",
    "\n",
    "def training_generator():\n",
    "    for images, labels in train_iterator:\n",
    "        yield (images, one_hot_encode(labels))\n",
    "\n",
    "def validation_generator():\n",
    "    for images, labels in val_iterator:\n",
    "        yield (images, one_hot_encode(labels))\n",
    "\n",
    "batch_size = 20\n",
    "# Use the defined generator functions in model.fit\n",
    "# Fit the model\n",
    "hist = model.fit(\n",
    "    training_generator(),\n",
    "    steps_per_epoch=train_size // batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator(),\n",
    "    validation_steps=val_size // batch_size,\n",
    "    callbacks=[tensorboard_callback, early_stopping]\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566d09f-77a4-4b38-98ae-1261f3d2710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history\n",
    "training_accuracy = hist.history['accuracy'][-1]\n",
    "print(\"Overall Training Accuracy:\", training_accuracy)\n",
    "import numpy as np\n",
    "\n",
    "training_accuracy_values = hist.history['accuracy']\n",
    "average_training_accuracy = np.mean(training_accuracy_values)\n",
    "print(\"Average Training Accuracy:\", average_training_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2157b9-f962-427e-bced-35019bb2b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(batch_size=20):\n",
    "    \"\"\"\n",
    "    Generator function for test data.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Batch size for generating test data.\n",
    "\n",
    "    Yields:\n",
    "        A tuple containing (image, one-hot encoded label).\n",
    "    \"\"\"\n",
    "    for image, label in test:\n",
    "        yield (image, one_hot_encode(label))  # Directly yield the tuple\n",
    "\n",
    "val = data.skip(train_size).take(val_size).cache()\n",
    "\n",
    "# Fit the model with the finite validation dataset\n",
    "hist = model.fit(\n",
    "    training_generator(),\n",
    "    steps_per_epoch=20,  # Adjust this as needed\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator(),\n",
    "    validation_steps=int(val_size / batch_size),  # Adjust this as needed\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Evaluate using the test generator\n",
    "test_loss, test_acc = model.evaluate(test_generator())\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db6754-7a4e-43a2-a58e-ae47636f7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))  # Adjust figure size as desired\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d907cbf8-e5a9-4e12-8964-b900eabbedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to yield test data batches\n",
    "def test_generator(batch_size=20):\n",
    "    \"\"\"\n",
    "    Generator function for test data.\n",
    "    Args:\n",
    "        batch_size (int): Batch size for generating test data.\n",
    "    Yields:\n",
    "        A tuple containing (image, one-hot encoded label).\n",
    "    \"\"\"\n",
    "    for images, labels in test:\n",
    "        yield (images, one_hot_encode(labels))\n",
    "\n",
    "# Evaluate using the test generator\n",
    "test_loss, test_acc = model.evaluate(test_generator(), steps=test_steps)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Collect true labels and predictions\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "\n",
    "for images, labels in test_generator():\n",
    "    predictions = model.predict(images)\n",
    "    test_predictions.extend(np.argmax(predictions, axis=1))\n",
    "    test_labels.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "test_labels = np.array(test_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'],  # Replace with your class labels\n",
    "            yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'])  # Replace with your class labels\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "18a5e3e225eb6ef91d49d13ed99666bfa258911c9f1e0e40e1b0a216f12a06e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
